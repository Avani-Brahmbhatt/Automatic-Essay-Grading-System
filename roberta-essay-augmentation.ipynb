{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10984033,"sourceType":"datasetVersion","datasetId":6836113}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install nlpaug numpy pandas tqdm torch transformers sentencepiece gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:19:36.836519Z","iopub.execute_input":"2025-03-26T05:19:36.836825Z","iopub.status.idle":"2025-03-26T05:19:41.690176Z","shell.execute_reply.started":"2025-03-26T05:19:36.836801Z","shell.execute_reply":"2025-03-26T05:19:41.689247Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2025.1.31)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nimport nlpaug.augmenter.word as naw\nfrom nlpaug.util.file.download import DownloadUtil\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:19:46.710231Z","iopub.execute_input":"2025-03-26T05:19:46.710562Z","iopub.status.idle":"2025-03-26T05:20:22.701628Z","shell.execute_reply.started":"2025-03-26T05:19:46.710535Z","shell.execute_reply":"2025-03-26T05:20:22.700963Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load dataset\nfile_path = '/kaggle/input/17k-essays/essay_training_set.csv'\ndf = pd.read_csv(file_path).dropna()\n\nprint(f\"Full dataset size: {len(df)}\")\nprint(\"Original score distribution:\")\nprint(df['score'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:20:24.498849Z","iopub.execute_input":"2025-03-26T05:20:24.499516Z","iopub.status.idle":"2025-03-26T05:20:25.266096Z","shell.execute_reply.started":"2025-03-26T05:20:24.499485Z","shell.execute_reply":"2025-03-26T05:20:25.265293Z"}},"outputs":[{"name":"stdout","text":"Full dataset size: 17645\nOriginal score distribution:\nscore\n1    1252\n2    4723\n3    6280\n4    3926\n5     970\n6     494\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Split into train and validation sets (80% train, 20% validation)\ntrain_df = df.sample(frac=0.8, random_state=42)\nval_df = df.drop(train_df.index)\n\nprint(f\"\\nTraining set size: {len(train_df)}\")\nprint(\"Training score distribution:\")\nprint(train_df['score'].value_counts().sort_index())\nprint(f\"Validation set size: {len(val_df)}\")\nprint(\"Validation score distribution:\")\nprint(val_df['score'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:20:34.100599Z","iopub.execute_input":"2025-03-26T05:20:34.100957Z","iopub.status.idle":"2025-03-26T05:20:34.114434Z","shell.execute_reply.started":"2025-03-26T05:20:34.100931Z","shell.execute_reply":"2025-03-26T05:20:34.113526Z"}},"outputs":[{"name":"stdout","text":"\nTraining set size: 14116\nTraining score distribution:\nscore\n1    1002\n2    3758\n3    5040\n4    3123\n5     781\n6     412\nName: count, dtype: int64\nValidation set size: 3529\nValidation score distribution:\nscore\n1     250\n2     965\n3    1240\n4     803\n5     189\n6      82\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# RoBERTa-based augmenter (contextual embeddings)\nroberta_aug = naw.ContextualWordEmbsAug(\n    model_path='roberta-base', \n    action=\"substitute\",  # or \"insert\"\n    aug_p=0.3, \n    aug_min=1, \n    aug_max=5,\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:20:43.787578Z","iopub.execute_input":"2025-03-26T05:20:43.787971Z","iopub.status.idle":"2025-03-26T05:20:48.115109Z","shell.execute_reply.started":"2025-03-26T05:20:43.787944Z","shell.execute_reply":"2025-03-26T05:20:48.114123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee1b61b34b44a21bb0e78d8728d2235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5162983486d7485c94075616d606bd5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dccc03211c224c299d8ac8e78ccedc60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7010dbdbb50c44a4b30e1ddd1c4a3b9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4cc483035e04c7484ecac4b618b6981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b099a2acd66d41a18629cb9e895a1c38"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Example text\ntext = \"Data augmentation is important for NLP tasks.\"\naugmented_text = roberta_aug.augment(text)\n\nprint(f\"Original: {text}\")\nprint(f\"Augmented: {augmented_text}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:20:54.335033Z","iopub.execute_input":"2025-03-26T05:20:54.335379Z","iopub.status.idle":"2025-03-26T05:20:55.070436Z","shell.execute_reply.started":"2025-03-26T05:20:54.335354Z","shell.execute_reply":"2025-03-26T05:20:55.069550Z"}},"outputs":[{"name":"stdout","text":"Original: Data augmentation is important for NLP tasks.\nAugmented: ['Data sources are important across NLP tasks.']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#Augmentation logic (only for training set)\ntarget_count = 3990\nminority_scores = [1, 5, 6]\nmajority_scores = [2, 3, 4]\n\naugmented_texts = []\naugmented_scores = []\n\naugmenter = roberta_aug  # For RoBERTa\n\n# Augment minority classes in training set\nfor score in minority_scores:\n    minority_df = train_df[train_df['score'] == score]\n    original_count = len(minority_df)\n    augmentation_factor = max(1, min(int(target_count / original_count), 12))\n    \n    print(f\"\\nAugmenting minority score {score} from {original_count} to ~{target_count}\")\n    print(f\"Each essay augmented {augmentation_factor} times\")\n    \n    with tqdm(total=original_count * augmentation_factor, desc=f\"Score {score} Progress\") as pbar:\n        for _, row in minority_df.iterrows():\n            augmented_texts.append(row['full_text'])  # Original\n            augmented_scores.append(row['score'])\n            pbar.update(1)\n            for _ in range(augmentation_factor - 1):\n                new_text = augmenter.augment(row['full_text'])[0]  # nlpaug returns a list\n                augmented_texts.append(new_text)\n                augmented_scores.append(row['score'])\n                pbar.update(1)\n\n# Adjust majority classes in training set\nfor score in majority_scores:\n    majority_df = train_df[train_df['score'] == score]\n    original_count = len(majority_df)\n    \n    if original_count > target_count:\n        sampled_df = majority_df.sample(n=target_count, random_state=42)\n        print(f\"\\nDownsampling majority score {score} from {original_count} to {target_count}\")\n        adjustment_factor = 1\n    else:\n        adjustment_factor = max(1, min(int(target_count / original_count), 2))\n        sampled_df = majority_df\n        print(f\"\\nAdjusting majority score {score} from {original_count} to ~{target_count}\")\n        print(f\"Each essay augmented {adjustment_factor} times\")\n    \n    with tqdm(total=len(sampled_df) * adjustment_factor, desc=f\"Score {score} Progress\") as pbar:\n        for _, row in sampled_df.iterrows():\n            augmented_texts.append(row['full_text'])  # Original\n            augmented_scores.append(row['score'])\n            pbar.update(1)\n            for _ in range(adjustment_factor - 1):\n                new_text = augmenter.augment(row['full_text'])[0]\n                augmented_texts.append(new_text)\n                augmented_scores.append(row['score'])\n                pbar.update(1)\n\n# Create augmented training DataFrame\naugmented_train_df = pd.DataFrame({'full_text': augmented_texts, 'score': augmented_scores})\n\n# Combine with validation set (unaugmented)\nfinal_df = pd.concat([augmented_train_df, val_df], ignore_index=True)\n\nprint(f\"\\nOriginal training set size: {len(train_df)}\")\nprint(f\"Augmented training set size: {len(augmented_train_df)}\")\nprint(f\"Validation set size (unchanged): {len(val_df)}\")\nprint(f\"Final combined dataset size: {len(final_df)}\")\nprint(\"Final score distribution:\")\nprint(final_df['score'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:21:15.603483Z","iopub.execute_input":"2025-03-26T05:21:15.603801Z","iopub.status.idle":"2025-03-26T05:47:38.807791Z","shell.execute_reply.started":"2025-03-26T05:21:15.603776Z","shell.execute_reply":"2025-03-26T05:47:38.806899Z"}},"outputs":[{"name":"stdout","text":"\nAugmenting minority score 1 from 1002 to ~3990\nEach essay augmented 3 times\n","output_type":"stream"},{"name":"stderr","text":"Score 1 Progress: 100%|██████████| 3006/3006 [05:07<00:00,  9.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAugmenting minority score 5 from 781 to ~3990\nEach essay augmented 5 times\n","output_type":"stream"},{"name":"stderr","text":"Score 5 Progress: 100%|██████████| 3905/3905 [12:04<00:00,  5.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAugmenting minority score 6 from 412 to ~3990\nEach essay augmented 9 times\n","output_type":"stream"},{"name":"stderr","text":"Score 6 Progress: 100%|██████████| 3708/3708 [09:11<00:00,  6.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAdjusting majority score 2 from 3758 to ~3990\nEach essay augmented 1 times\n","output_type":"stream"},{"name":"stderr","text":"Score 2 Progress: 100%|██████████| 3758/3758 [00:00<00:00, 21498.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nDownsampling majority score 3 from 5040 to 3990\n","output_type":"stream"},{"name":"stderr","text":"Score 3 Progress: 100%|██████████| 3990/3990 [00:00<00:00, 21339.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nAdjusting majority score 4 from 3123 to ~3990\nEach essay augmented 1 times\n","output_type":"stream"},{"name":"stderr","text":"Score 4 Progress: 100%|██████████| 3123/3123 [00:00<00:00, 19310.47it/s]","output_type":"stream"},{"name":"stdout","text":"\nOriginal training set size: 14116\nAugmented training set size: 21490\nValidation set size (unchanged): 3529\nFinal combined dataset size: 25019\nFinal score distribution:\nscore\n1    3256\n2    4723\n3    5230\n4    3926\n5    4094\n6    3790\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"augmented_train_df.to_csv('augmented_train_dataset.csv', index=False)\nval_df.to_csv('validation_dataset.csv', index=False)\nfinal_df.to_csv('complete_essay_dataset.csv', index=False)\nprint(\"Datasets saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T05:51:28.540800Z","iopub.execute_input":"2025-03-26T05:51:28.541090Z","iopub.status.idle":"2025-03-26T05:51:30.790170Z","shell.execute_reply.started":"2025-03-26T05:51:28.541069Z","shell.execute_reply":"2025-03-26T05:51:30.789250Z"}},"outputs":[{"name":"stdout","text":"Datasets saved!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
